{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Generative Adversarial Networks \n",
    "Based on tutorials by Ian Goodfellow et al.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "### By Jeremy Hartmann "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"./images/Yann%20LeCun%20-%20Best%20thing%20since%20sliced%20bread.png\" alt=\"Drawing\" style=\"width: 100%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Build some hype\n",
    "- Yann LeCun\n",
    "- most interesting idea in the last ten year in Machine Learning\n",
    "- After reading about it, Agree. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "- Motivation\n",
    "- What are GANs?\n",
    "- Taxonomy of Generative Models\n",
    "- Cost Function\n",
    "- Intuition\n",
    "- Future Work and Research\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Simulate many possible futures for planning or simulated RL (Reinforcement Learning)\n",
    "- Semi-Supervised learning (Missing data)\n",
    "- Multi-model output\n",
    "- Realistic generation tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Simulated Futures:\n",
    "- model learns to project different states of the world from the current states \n",
    "\n",
    "Semi-supervised learning:\n",
    "- Train on incomplete or missing data. Say if you have data that is only partially labeled. Labeling data is one of the most time consume efforts in ML. Needs to be done by humans (Mechanical Turk)\n",
    "\n",
    "Multi-Model output:\n",
    "- A single input can correspond to many correct answers from a set of answers. All equally valid (sitting down in a room, all chairs are valid)\n",
    "\n",
    "Realistic Generation tasks:\n",
    "- Generate realsitic images. Audio, Speech, etc...\n",
    "\n",
    "Some current research examples of GANs follows..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Interactive Image Generation (Zhu et al. 2016)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/iGAN_Zhu2016.gif\" alt=\"Drawing\" style=\"height: 100%;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "iGAN Zhu et al 2016 ( Generative visual manipulation on the natural image manifold)\n",
    "- The user edits in the canvas which updates the projection from the latent space into the image manifold. \n",
    "- Colors, line contours are used to interpolate the latent space. \n",
    "- Many possible outputs are on the right as the user updates. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 3D GAN (Wu et al. 2016)\n",
    "![3DGan_Wu2016.gif](./images/3DGan_Wu2016.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "3D GAN Wu et al. 2016 (MIT) Learning a Probabilistic Latent Space of Object Shapes via 3D Generative-Adversarial Modeling\n",
    "- Projects the latent space into a 3-dimensional voxel space using a volumetric CNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What are GANs?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![generative-adversarial-network_Diagram_KDNuggets.png](./images/generative-adversarial-network_Diagram_KDNuggets.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Generator: \n",
    "- samples from the prior distribution of the latent space. \n",
    "- Latent space -- essential some randomness to produce images. \n",
    "- Generates samples for a minibatch is fed into the discriminator\n",
    "- Usually is some form of deconvolution (transpose stride) net. \n",
    "\n",
    "Discriminator:\n",
    "- essentially a binary classifier that determines weather the input is fake or real\n",
    "- Can be a feed-forward (ConvNet)\n",
    "\n",
    "Simultaneous Gradient Descent\n",
    "- Both minibatches are processed. \n",
    "- And both the generator and discriminator will update there weights based on the cost function. \n",
    "\n",
    "Analogy (Grad student/Supervisor):\n",
    "- The grad student and supervisor\n",
    "- Grad student produces research papers (Generator) to the supervisor (Discriminator). \n",
    "- Grad student wants to maximise the supervisors grade/evaulation.\n",
    "- Supervisor is very meticulous, and tries to find absolutly every details wrong with it, lowering your grade. \n",
    "- Feedback is given to Grad student to improve. \n",
    "- Supervisor improves evaulation techniques.\n",
    "- And so the cycle continues...\n",
    "\n",
    "Image form KDNuggets: (http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The Latent Space\n",
    "- Source of randomness but more meaningful. \n",
    "- High dimensional vector space of the real data's manifold. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LatentSpaceExample-TomWhite.PNG](./images/LatentSpaceExample-TomWhite.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The high dimension data:\n",
    "- Key important thing to understand in GANs\n",
    "- Could be categories like gender, smiling, etc....\n",
    "- People wearing glasses. \n",
    "- Image: (Tom White, 2016) Sampling Generative Networks\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Vector Arithmetic on the Latent Space\n",
    "\n",
    "![VectorArithmetic_1_Radford-2016.PNG](./images/VectorArithmetic_1_Radford-2016.PNG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Vector arithmetic:\n",
    "- Alec Radford et al. 2016 LCLR. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\n",
    "- Introduced DCGAN (Deep Convolutional GAN) Which are really popular and one of the most stable implementation of GANs on images.\n",
    "\n",
    "- The concept of the latent space is very important to understanding GANs\n",
    "\n",
    "- have a representation of a man with glasses (not the actual image!)\n",
    "- have a representaion of a man without glasses. \n",
    "- Plus a women without glasses\n",
    "\n",
    "- Theses are the vectors in the latent space. \n",
    "\n",
    "What do we get?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Vector Arithmetic\n",
    "\n",
    "- Women with glasses (obviously!)\n",
    "\n",
    "![VectorArithmetic_2_Radford-2016.PNG](./images/VectorArithmetic_2_Radford-2016.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Women with glasses\n",
    "- the latent vector representation of the this concept. \n",
    "- each image is a perturbation on the latent vector. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "- Easy to understand at a high level\n",
    "- Lots of intrecracies at the low level\n",
    "- Many interesting research questions (later...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Taxonomy of Generative Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![TaxonomyOfGenerativeModels.PNG](./images/TaxonomyOfGenerativeModels.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Taxonomy of Generative Models:\n",
    "- The three most popular generative models are \n",
    " - FVBN (Fully Visible Belief Nets) - WaveNet\n",
    " - GAN (What we are discussing!)\n",
    " - Variational Autoencoders\n",
    " \n",
    " \n",
    "- Explicit Models\n",
    " - Defines an explicit density function.\n",
    " - Captures all the complexity of the model. \n",
    " - Fairly straight forward to train, plug the model definition of the density function into the expression for the likelihood and follow the gradient uphill. \n",
    " - Tractabile (model is computationally computatble)\n",
    " - Approximate (need to invoke some kinde of Monte Carlo or variational approximation). \n",
    " - VAE (Kingma et al. 2014)\n",
    " - FVBN (WaveNet - Oord 2016)\n",
    " \n",
    "- Implicit Models\n",
    " - Does not explicitly represent the probability distrubution over the space where the data lies. \n",
    " - Provides a means to interact less directly usually by sampling from it. \n",
    " - Generative Stochastic Network (Bengio et al. 2014). \n",
    " \n",
    " Markov Chains:\n",
    " - Do not scale well to higher dimensions\n",
    " \n",
    " NonLinear ICA\n",
    " - Ivertable function G (Cost)\n",
    " - z and x must be same size. \n",
    " \n",
    " FVBN:\n",
    " - Slow to generate samples\n",
    " \n",
    " \n",
    " \n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Fully Visible Belief Nets (FVBN) - WaveNet (Oord et al. 2016)\n",
    "![WaveNet_BlogPost-Fig2-Anim-160908-r01.gif](./images/WaveNet_BlogPost-Fig2-Anim-160908-r01.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Disadvantage:\n",
    "- (FVBN) Not parallel - GANs can generate all samples in parallel. \n",
    "- Each sample is generated sequentially. 2 min for 1 seccond of audio. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Variational AutoEncoders (Kingma et al. 2013)\n",
    "![variational-autoencoder-faces._AlecRadford.jpg](./images/variational-autoencoder-faces._AlecRadford.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Variational Autoencoders:\n",
    "- Produce blurry images and lower quality samples (GANs produce subjectivly better examples, hard to prove)\n",
    "- Might not be asymptotically consistent (Yet to be proven).\n",
    " - Even with infinite data, the gap between the model and the data will not converge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Discriminator\n",
    "   $J^{(D)} (\\theta^{(D)}, \\theta^{(G)}) = \\\\\n",
    "   -\\frac{1}{2} \\mathbb{E}_{x \\sim p_{data}} \\log{(D(x))} - \\frac{1}{2} \\mathbb{E}_{z} \\log{(1 - D(G(z)))}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "The Cost Function\n",
    "- Minimize\n",
    "- What's happening here is really interesting. \n",
    "- It is a standard cross entropy cost that is minimized when training a standard binary classifier. \n",
    "- The Discriminator wants to maximize the log probability of D(x)\n",
    "- Minimize the log probability of D(G(z))\n",
    "\n",
    "- Expected value of x in the data for the log probability of the discriminator\n",
    "- Expected value of z for the log probability of the discriminator with respect to the generator. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The real samples\n",
    "# $-\\frac{1}{2} \\mathbb{E}_{x \\sim p_{data}} \\log{(D(x))}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Here we have the expected value of x from the data probability distrubition which are our real images. \n",
    "- This could be from MNIST, ImageNet etc....\n",
    "- Wants to maximize log probability of D(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Latent Space Samples\n",
    "# $- \\frac{1}{2} \\mathbb{E}_{z} \\log{(1 - D(G(z)))}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is the expectrd value z over the prior probability distrubition of the latent space. \n",
    "- Z is a (latent space) source of noise for the generator. \n",
    "- the latent space vector can be larger or smaller then x. \n",
    "- Wants to minimize D(G(z)) as these are the ones that need improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Another View (Gradient Ascent)\n",
    "\n",
    "### $\\nabla_{\\theta_d} \\frac{1}{m} \\sum^{m}_{i=1} \\big[ \\log{D(x^{(i)})} +  \\\\\n",
    "\\log{(1 - D(G(z^{(i)})}) \\big]$\n",
    "\n",
    "- Key: The cost function evaluates two  minibatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "KEY!! Crux: the cost function for the discriminator takes a minibatch from the Generator and a minibatch from the real data distrubution. \n",
    "- Nabla representing gradient ascent\n",
    "- m training examples\n",
    "- Images... or something else\n",
    "- Average over the log probabilities of the training set (minibatch)\n",
    "\n",
    "- Medium article from Julien (https://medium.com/@awjuliani/generative-adversarial-networks-explained-with-a-classic-spongebob-squarepants-episode-54deab2fce39). \n",
    "- Gradient ascent (maximize!)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Minimax Game\n",
    "\n",
    "- zero-sum Game\n",
    "\n",
    " $J^{(D)} = -\\frac{1}{2} \\mathbb{E}_{x \\sim p_{data}} \\log{(D(x))} -  \\\\ \n",
    " \\frac{1}{2} \\mathbb{E}_{z} \\log{(1 - D(G(z)))}$\n",
    " \n",
    " $J^{(G)} = -J^{(D)}$\n",
    " \n",
    "- Where the saddle point is the Nash equilibrium.  \n",
    "- Generator minimizes the log probability of the discriminator being correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Minimax Game\n",
    "- The generator recieves the negative of what the discriminator gernerates\n",
    "- The equilbrium is the saddle point of the discriminator loss\n",
    "- Resembles the Jensen-Shannon divergence instead of the KL divergence. \n",
    "- Heurstics are used to help the generator avoid non-convergence. (See Ian Goodfellow Tutorial Paper)\n",
    "- Issues are created by this as the minmax is not garunteed and could form a maxmin....\n",
    " - Mode collapse problem (later..)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Intuition behind GANs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MSE vs GANs\n",
    "- GANs do not use Mean Squared Error\n",
    "\n",
    "![IntuitiveMSE_HowGANsWork.PNG](./images/IntuitiveMSE_HowGANsWork.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "MSE vs GANs\n",
    "- Unlike most other supervised learning techniques, GANs do not use mean squared error. \n",
    "- Given the natural image manifold (red). \n",
    "- MSE will averagea over all possible solutions (Blue) resulting in a blurry  and low quality sample. \n",
    "- GANs will choose one correct solution out of all correct solutions. \n",
    "- Could learn blurry images. \n",
    "- When the discriminator recieves any one correct solution, it will prop it up as a good thing, unlike MSE. \n",
    "- Image (Ledig et al. 2016  -- SRGAN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Mode collapse problem\n",
    "- Other Games: Understand how continuous high-dimensional non-convex games converge\n",
    "- The Convergence problem\n",
    "- Evaluation of generative models. \n",
    "- Discrete outputs\n",
    "- Using the latent code $z$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Other games\n",
    "- Game theory in general and convergence. \n",
    "\n",
    "Evaulation\n",
    "- How do we quantitatively rate the generated results\n",
    "\n",
    "Discrete outputs:\n",
    "- For NLP (Natural language processing)\n",
    "\n",
    "Using the latent code\n",
    "- Latent Code has very high level semantic information from the real data distrubution. \n",
    "- Not clear how to use this. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "## Papers\n",
    "See BibTex in Repo\n",
    "\n",
    "\n",
    "## Repo\n",
    "https://github.com/jjhartmann/NN-GAN-Presentation\n",
    "\n",
    "\n",
    "## Websites \n",
    "\n",
    "\n",
    "- http://www.deeplearningbook.org/contents/generative_models.html // Ians book on Deep Learning\n",
    "- https://affinelayer.com/pixsrv/ // Image to Image Tensorflow implementation for the paper by Isola et al.\n",
    "- https://phillipi.github.io/pix2pix/ // Image to Image webstie. \n",
    "- https://github.com/goodfeli // Ian Goodfellow GitHub\n",
    "- https://github.com/damianavila/RISE // Jupyter notebook slide extension\n",
    "- https://github.com/soumith/ganhacks/blob/master/README.md // Awesome hacks/tricks for GAN training.\n",
    "- https://www.youtube.com/playlist?list=PLJscN9YDD1buxCitmej1pjJkR5PMhenTF // 2016 NIPS tutorial\n",
    "- https://github.com/adeshpande3/Generative-Adversarial-Networks // GAN tensortflow implementation\n",
    "- https://www.tensorflow.org/get_started/mnist/pros // Tensorflow Tutorial\n",
    "- https://blog.openai.com/generative-models/ // OpenAI blog\n",
    "- https://deepmind.com/blog/wavenet-generative-model-raw-audio/ // WaveNet\n",
    "- http://distill.pub/2016/deconv-checkerboard/ // Blog on why generators porudce checkerboard artifacts\n",
    "- http://3dgan.csail.mit.edu/ // 3D Gan\n",
    "- http://www.kdnuggets.com/2017/01/generative-adversarial-networks-hot-topic-machine-learning.html // Julien on GANs\n",
    "- https://github.com/awjuliani/TF-Tutorials // Tensorflow impl for DCGAN\n",
    "- https://jaan.io/what-is-variational-autoencoder-vae-tutorial/ // Tutorial on VAEs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ORPHANS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Unrolled GAN (Metz et al. 2016)\n",
    "![ModeCollapse_solutions_unrolledGAN.PNG](./images/ModeCollapse_solutions_unrolledGAN.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Original GAN Flow Chart\n",
    "![GAN%20Flow%20Graph.PNG](./images/GAN%20Flow%20Graph.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Coordinating Global Structure\n",
    "![Gans%20on%20imageNet_coordinating%20global%20structure.PNG](./images/Gans%20on%20imageNet_coordinating%20global%20structure.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Perspective\n",
    "![Gans%20on%20imageNet_perspective.PNG](./images/Gans%20on%20imageNet_perspective.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Counting\n",
    "![Gans%20on%20imageNet.PNG](./images/Gans%20on%20imageNet.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Problem With Batch Normalization\n",
    "![Problem%20with%20batch%20normalization%20-%20correlations..PNG](./images/Problem%20with%20batch%20normalization%20-%20correlations..PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Text to Image Synthesis\n",
    "![text-to-image-synthesis.PNG](./images/text-to-image-synthesis.PNG)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Text to Image Synthesis: Network\n",
    "![TextToImageGANetwork_Reed2016.png](./images/TextToImageGANetwork_Reed2016.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How does this work in code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#These two placeholders are used for input into the generator and discriminator, respectively.\n",
    "z_in = tf.placeholder(shape=[None,z_size],dtype=tf.float32) #Random vector\n",
    "real_in = tf.placeholder(shape=[None,32,32,1],dtype=tf.float32) #Real images\n",
    "\n",
    "Gz = generator(z_in) #Generates images from random z vectors\n",
    "Dx = discriminator(real_in) #Produces probabilities for real images\n",
    "Dg = discriminator(Gz,reuse=True) #Produces probabilities for generator images\n",
    "\n",
    "#These functions together define the optimization objective of the GAN.\n",
    "d_loss = -tf.reduce_mean(tf.log(Dx) + tf.log(1.-Dg)) #This optimizes the discriminator.\n",
    "g_loss = -tf.reduce_mean(tf.log(Dg)) #This optimizes the generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "## See References for full code and tensorflow examples..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Super Resolution GAN (Ledig et al. 2015)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SuperResolutionGAN_Ledig.PNG](./images/SuperResolutionGAN_Ledig.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Ledig et al (2016)  SRGAN (Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network)\n",
    "- bicubic interpolation, \n",
    "- deep residual network optimized for MSE, \n",
    "- deep residual generative adversarial network optimized for a loss more sensitive to human perception, \n",
    "- original HR image. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Predicting Next Video Frame  (Lotter et al. 2016)\n",
    "\n",
    "![NextFramePrediction_MSEvsGAN_Lotter-2016.PNG](./images/NextFramePrediction_MSEvsGAN_Lotter-2016.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "- MSE - the image does not hold much detail as the algorithm blurs over many possible answers\n",
    "- AL (adverarial loss) Chooses one possible correct solution. Image is sharper. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Mode Collapse Problem\n",
    "\n",
    "- The GAN remains stuck cycling through modes. \n",
    "- $\\min_G \\max_D V(G, D) \\neq  \\max_D \\min_G V(G, D)$\n",
    "\n",
    "![ModeCollapse_issues_Metz-2016.PNG](./images/ModeCollapse_issues_Metz-2016.PNG)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Min Max is not gauranteed. \n",
    "- Could also produce max min, which is a result of the simulataneous  gradient descent. \n",
    "- Max Min: then the generator tries to minimize the error for a particular set (minibatch) of samples which results in the focus on a single mode. \n",
    "\n",
    "Here we can see that at various iterations in the training, different modes are targeted. \n",
    "- There has been research in Unrolled GANs by Metz et al. 2016 that look to have minimized this issue. But is it solved?\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### KL and Reverse KL Divergence\n",
    "![KL%20v%20Reverse%20KL%20diagram.PNG](./images/KL%20v%20Reverse%20KL%20diagram.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Jensen-Shannan Divergence (Symmetric)\n",
    "- Can be thought of as the reverse of the KL (Kullback–Leibler) divergence\n",
    "- Which measures how one probability diverges from the other. \n",
    "\n",
    "- P - real probability distribution\n",
    "- q - model\n",
    "- Maximum Likelihood - averages over the desnsity\n",
    "- Reverse KL - minimizes the divergence for a single mode in the desnsity distrubtion. \n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
